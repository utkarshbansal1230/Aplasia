{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdde78b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============== STARTING GLOBAL GRID SEARCH ================\n",
      "Optimizing parameters on the entire dataset first...\n",
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n",
      "\n",
      ">>> BEST PARAMETERS FOUND: {'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 200, 'subsample': 0.8}\n",
      ">>> BEST BALANCED ACCURACY: 0.5941\n",
      "============================================================\n",
      "\n",
      "#################### PROCESSING FOLD 0 #####################\n",
      "Samples -> Train: 733, Val: 79, Test: 198\n",
      "Fold 0 Balanced Accuracy: 0.5825\n",
      "Fold 0 Long Class Recall:   0.2500\n",
      "\n",
      ">>> Fold 0 MISSED 3 'LONG' CASES:\n",
      " chemo_hadm_id  Actual_Class  Predicted_Class  Actual_Days\n",
      "      21176832             2                1         41.0\n",
      "      25841662             2                1         24.0\n",
      "      27576498             2                0         25.0\n",
      "\n",
      "Confusion Matrix:\n",
      "[[156  19   1]\n",
      " [  6  11   1]\n",
      " [  1   2   1]]\n",
      "----------------------------------------\n",
      "\n",
      "#################### PROCESSING FOLD 1 #####################\n",
      "Samples -> Train: 721, Val: 85, Test: 204\n",
      "Fold 1 Balanced Accuracy: 0.5136\n",
      "Fold 1 Long Class Recall:   0.2500\n",
      "\n",
      ">>> Fold 1 MISSED 3 'LONG' CASES:\n",
      " chemo_hadm_id  Actual_Class  Predicted_Class  Actual_Days\n",
      "      27627583             2                0         39.0\n",
      "      27756905             2                1         22.0\n",
      "      28095196             2                1         22.0\n",
      "\n",
      "Confusion Matrix:\n",
      "[[157  23   4]\n",
      " [  8   7   1]\n",
      " [  1   2   1]]\n",
      "----------------------------------------\n",
      "\n",
      "#################### PROCESSING FOLD 2 #####################\n",
      "Samples -> Train: 731, Val: 72, Test: 207\n",
      "Fold 2 Balanced Accuracy: 0.4876\n",
      "Fold 2 Long Class Recall:   0.0000\n",
      "\n",
      ">>> Fold 2 MISSED 2 'LONG' CASES:\n",
      " chemo_hadm_id  Actual_Class  Predicted_Class  Actual_Days\n",
      "      21095202             2                0         36.0\n",
      "      29179248             2                0         32.0\n",
      "\n",
      "Confusion Matrix:\n",
      "[[164  18   2]\n",
      " [  8  12   1]\n",
      " [  2   0   0]]\n",
      "----------------------------------------\n",
      "\n",
      "#################### PROCESSING FOLD 3 #####################\n",
      "Samples -> Train: 733, Val: 83, Test: 194\n",
      "Fold 3 Balanced Accuracy: 0.5804\n",
      "Fold 3 Long Class Recall:   0.2857\n",
      "\n",
      ">>> Fold 3 MISSED 5 'LONG' CASES:\n",
      " chemo_hadm_id  Actual_Class  Predicted_Class  Actual_Days\n",
      "      20866387             2                1         30.0\n",
      "      22491397             2                1         23.0\n",
      "      27804451             2                0         23.0\n",
      "      28627528             2                1         23.0\n",
      "      28668281             2                0         38.0\n",
      "\n",
      "Confusion Matrix:\n",
      "[[146  14   4]\n",
      " [  9  13   1]\n",
      " [  2   3   2]]\n",
      "----------------------------------------\n",
      "\n",
      "#################### PROCESSING FOLD 4 #####################\n",
      "Samples -> Train: 721, Val: 82, Test: 207\n",
      "Fold 4 Balanced Accuracy: 0.4189\n",
      "Fold 4 Long Class Recall:   0.0000\n",
      "\n",
      ">>> Fold 4 MISSED 3 'LONG' CASES:\n",
      " chemo_hadm_id  Actual_Class  Predicted_Class  Actual_Days\n",
      "      20399542             2                1         25.0\n",
      "      20478619             2                0         26.0\n",
      "      24358862             2                1         36.0\n",
      "\n",
      "Confusion Matrix:\n",
      "[[169  14   0]\n",
      " [ 13   7   1]\n",
      " [  1   2   0]]\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "============================================================\n",
      "FINAL AVERAGE BALANCED ACCURACY: 0.5166\n",
      "FINAL AVERAGE LONG CLASS RECALL: 0.1571\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import classification_report, confusion_matrix, balanced_accuracy_score\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "\n",
    "df_mine = pd.read_csv(\"/Users/utkarshbansal/Desktop/APLASIA/final.csv\")\n",
    "\n",
    "# 2. Check for columns\n",
    "target_col = 'target_first_episode_duration'\n",
    "id_col_name = 'chemo_hadm_id'\n",
    "\n",
    "if target_col not in df_mine.columns:\n",
    "    raise ValueError(f\"Column '{target_col}' not found\")\n",
    "\n",
    "\n",
    "bins = [-1, 9, 20, np.inf]\n",
    "labels = [0, 1, 2]\n",
    "df_mine['target_class'] = pd.cut(df_mine[target_col], bins=bins, labels=labels).astype(int)\n",
    "\n",
    "\n",
    "print(\" STARTING GLOBAL GRID SEARCH \".center(60, '='))\n",
    "print(\"Optimizing parameters on the entire dataset first...\")\n",
    "\n",
    "# A.1 Prepare Global Data\n",
    "drop_cols_global = [id_col_name, target_col, 'target_class']\n",
    "X_global = df_mine.drop(columns=drop_cols_global)\n",
    "y_global = df_mine['target_class']\n",
    "\n",
    "global_weights = compute_sample_weight(class_weight='balanced', y=y_global) ## to address class imbalance\n",
    "## gives higher weight to minority class.\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [3, 4, 5],           \n",
    "    'learning_rate': [0.01, 0.05, 0.1], \n",
    "    'n_estimators': [100, 200],       \n",
    "    'colsample_bytree': [0.5, 0.8],   \n",
    "    'subsample': [0.8, 1.0]           \n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb.XGBClassifier(\n",
    "        objective='multi:softmax', \n",
    "        num_class=3, \n",
    "        random_state=42, \n",
    "        eval_metric='mlogloss'\n",
    "    ),\n",
    "    param_grid=param_grid,\n",
    "    scoring='balanced_accuracy', \n",
    "    cv=StratifiedKFold(n_splits=3), \n",
    "    verbose=1,\n",
    "    n_jobs=-1 \n",
    ")\n",
    "\n",
    "# A.5 Run the Search\n",
    "grid_search.fit(X_global, y_global, sample_weight=global_weights)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"\\n>>> BEST PARAMETERS FOUND: {best_params}\")\n",
    "print(f\">>> BEST BALANCED ACCURACY: {grid_search.best_score_:.4f}\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "\n",
    "fold_files = [f'fold_{i}.pkl' for i in range(5)]\n",
    "fold_scores = []\n",
    "long_class_recalls = []\n",
    "\n",
    "for fold_num, file_path in enumerate(fold_files):\n",
    "    \n",
    "    try:\n",
    "        with open(file_path, 'rb') as f:\n",
    "            original_train_ids, original_val_ids, original_test_ids = pickle.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Skipping Fold {fold_num}: File {file_path} not found.\")\n",
    "        continue\n",
    "\n",
    "    def filter_my_data(original_pairs):\n",
    "        valid_hadm_ids = set([pair[1] for pair in original_pairs])\n",
    "        return df_mine[df_mine[id_col_name].isin(valid_hadm_ids)]\n",
    "\n",
    "    df_train = filter_my_data(original_train_ids)\n",
    "    df_val   = filter_my_data(original_val_ids)\n",
    "    df_test  = filter_my_data(original_test_ids)\n",
    "\n",
    "    print(f\" PROCESSING FOLD {fold_num} \".center(60, '#'))\n",
    "    print(f\"Samples -> Train: {len(df_train)}, Val: {len(df_val)}, Test: {len(df_test)}\")\n",
    "\n",
    "    drop_cols = [id_col_name, target_col, 'target_class']\n",
    "    \n",
    "    X_train = df_train.drop(columns=drop_cols)\n",
    "    X_val   = df_val.drop(columns=drop_cols)\n",
    "    X_test  = df_test.drop(columns=drop_cols)\n",
    "\n",
    "    y_train = df_train['target_class']\n",
    "    y_val   = df_val['target_class']\n",
    "    y_test  = df_test['target_class']\n",
    "\n",
    "    weights_train = compute_sample_weight(class_weight='balanced', y=y_train)\n",
    "\n",
    "    model = xgb.XGBClassifier(\n",
    "        **best_params,              \n",
    "        objective='multi:softmax',\n",
    "        num_class=3,\n",
    "        random_state=42,\n",
    "        eval_metric='mlogloss',\n",
    "        early_stopping_rounds=20\n",
    "    )\n",
    "\n",
    "    # Training\n",
    "    if len(X_train) > 0 and len(X_val) > 0:\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            sample_weight=weights_train,\n",
    "            eval_set=[(X_val, y_val)],\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        if len(X_test) > 0:\n",
    "            y_pred = model.predict(X_test)\n",
    "            \n",
    "            bal_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "            fold_scores.append(bal_acc)\n",
    "            \n",
    "            # Detailed Report\n",
    "            report = classification_report(y_test, y_pred, target_names=['Short', 'Medium', 'Long'], output_dict=True)\n",
    "            \n",
    "            recall_long = report['Long']['recall']\n",
    "            long_class_recalls.append(recall_long)\n",
    "            \n",
    "            print(f\"Fold {fold_num} Balanced Accuracy: {bal_acc:.4f}\")\n",
    "            print(f\"Fold {fold_num} Long Class Recall:   {recall_long:.4f}\")\n",
    "\n",
    "            fold_results = pd.DataFrame({\n",
    "                'chemo_hadm_id': df_test[id_col_name],\n",
    "                'Actual_Class': y_test.values,\n",
    "                'Predicted_Class': y_pred,\n",
    "                'Actual_Days': df_test[target_col].values\n",
    "            })\n",
    "            \n",
    "            missed_long = fold_results[(fold_results['Actual_Class'] == 2) & (fold_results['Predicted_Class'] != 2)]\n",
    "            \n",
    "            if not missed_long.empty:\n",
    "                print(f\"\\n>>> Fold {fold_num} MISSED {len(missed_long)} 'LONG' CASES:\")\n",
    "                print(missed_long.to_string(index=False))\n",
    "            else:\n",
    "                print(\"\\n>>> Excellent! No 'Long' cases were missed in this fold.\")\n",
    "\n",
    "            print(\"\\nConfusion Matrix:\")\n",
    "            print(confusion_matrix(y_test, y_pred))\n",
    "            print(\"-\" * 40 + \"\\n\")\n",
    "            \n",
    "        else:\n",
    "            print(f\"Fold {fold_num}: No test samples found.\")\n",
    "    else:\n",
    "        print(f\"Fold {fold_num}: Not enough train/val samples.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "if len(fold_scores) > 0:\n",
    "    print(f\"FINAL AVERAGE BALANCED ACCURACY: {np.mean(fold_scores):.4f}\")\n",
    "    print(f\"FINAL AVERAGE LONG CLASS RECALL: {np.mean(long_class_recalls):.4f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afdc442",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_aplasia (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
